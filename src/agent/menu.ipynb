{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815fd710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: c:\\repos\\Hackathon-2025\\.venv\\Scripts\\python.exe\n",
      "uv: c:\\repos\\Hackathon-2025\\.venv\\Scripts\\uv.EXE\n"
     ]
    }
   ],
   "source": [
    "# Step to ensure that the venv is being used for the project not local copies, should point at .venv in project.\n",
    "import sys, shutil\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"uv:\", shutil.which(\"uv\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318439a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uv in c:\\repos\\hackathon-2025\\.venv\\lib\\site-packages (0.8.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.7 environment at: C:\\repos\\Hackathon-2025\\.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m13 packages\u001b[0m \u001b[2min 46ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# installs into the current Jupyter kernel environment\n",
    "%pip install -U uv \n",
    "#! to run shell commands\n",
    "!uv pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91436281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated imports with official MCP adapter loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# LangChain + MCP Setup for Menu Retrieval (HTTP-based for Jupyter)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Official MCP adapter imports for HTTP transport\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… Updated imports with official MCP adapter loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d30edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— MCP HTTP adapter setup ready!\n"
     ]
    }
   ],
   "source": [
    "# MCP Client Setup using Official Adapter with HTTP Transport\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Global MCP client for HTTP\n",
    "mcp_client = None\n",
    "\n",
    "async def create_mcp_tools():\n",
    "    \"\"\"Create MCP tools using the official LangChain MCP adapter with HTTP transport\"\"\"\n",
    "    global mcp_client\n",
    "    \n",
    "    try:\n",
    "        # Create MultiServerMCPClient with streamable_http transport\n",
    "        mcp_client = MultiServerMCPClient({\n",
    "            \"menu\": {\n",
    "                \"transport\": \"streamable_http\",\n",
    "                \"url\": os.getenv(\"MENU_MCP_URL\")\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Get tools from the MCP server\n",
    "        tools = await mcp_client.get_tools()\n",
    "        print(f\"Loaded {len(tools)} MCP tools: {[tool.name for tool in tools]}\")\n",
    "        return tools\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to MCP HTTP server: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"ðŸ”— MCP HTTP adapter setup ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a94bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Ready to load MCP tools via official adapter!\n"
     ]
    }
   ],
   "source": [
    "# Load MCP Tools using Official Adapter\n",
    "# The tools will be loaded dynamically when setting up the agent\n",
    "# No need to manually create tool wrappers - the adapter handles this automatically\n",
    "print(\"ðŸ› ï¸ Ready to load MCP tools via official adapter!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3221ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Agent setup function ready! Run the next cell to initialize.\n"
     ]
    }
   ],
   "source": [
    "async def setup_agent():\n",
    "    \"\"\"Setup LangChain agent with MCP tools using official adapter\"\"\"\n",
    "    \n",
    "    # Initialize LLM for Azure OpenAI\n",
    "    # can get this from Azure Open Ai service -> Azure Ai Foundary Portal\n",
    "    from langchain_openai import AzureChatOpenAI\n",
    "    \n",
    "    llm = AzureChatOpenAI(\n",
    "        deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),  # Your Azure deployment name\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "        api_version=os.getenv(\"AZURE_API_VERSION\"), \n",
    "        temperature=1\n",
    "    )\n",
    "    \n",
    "    # Load MCP tools using official adapter\n",
    "    tools = await create_mcp_tools()\n",
    "    \n",
    "    if not tools:\n",
    "        print(\"No MCP tools loaded. Make sure the MCP server is accessible.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loaded {len(tools)} MCP tools: {[tool.name for tool in tools]}\")\n",
    "    \n",
    "    # Create system prompt\n",
    "    system_prompt = \"\"\"You are an assistant that can help users get information about menu offerings from various restaurants.\n",
    "\n",
    "    You have access to multiple MCP tools for menu information, including:\n",
    "    - Searching for menu items by restaurant and cuisine\n",
    "    - Getting detailed menu item information\n",
    "    - Assisting with popular menu item recommendations\n",
    "    - Providing dietary information about menu items\n",
    "    - Filtering menu items by dietary preferences (e.g., vegan, gluten-free)\n",
    "    - And more...\n",
    "\n",
    "    When users ask about menu offerings, use these tools to provide comprehensive information.\n",
    "    Always be helpful and provide practical advice.\"\"\"\n",
    "    \n",
    "    # Create prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    \n",
    "    # Create agent\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "    # memory\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    # Create agent executor with tool logging callback and verbose output\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)\n",
    "    \n",
    "    return agent_executor\n",
    "\n",
    "# Initialize the agent (now async)\n",
    "agent_executor = None\n",
    "print(\"ðŸ¤– Agent setup function ready! Run the next cell to initialize.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b27257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing agent with MCP tools...\n",
      "Loaded 1 MCP tools: ['get_menu']\n",
      "Loaded 1 MCP tools: ['get_menu']\n",
      "LangChain agent with MCP tools ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ablackaller\\AppData\\Local\\Temp\\ipykernel_54776\\402740628.py:51: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent with MCP tools\n",
    "async def initialize_agent():\n",
    "    \"\"\"Initialize the agent with MCP tools\"\"\"\n",
    "    global agent_executor\n",
    "    print(\"Initializing agent with MCP tools...\")\n",
    "    agent_executor = await setup_agent()\n",
    "    if agent_executor:\n",
    "        print(\"LangChain agent with MCP tools ready!\")\n",
    "    else:\n",
    "        print(\"Failed to initialize agent. Check MCP server connection.\")\n",
    "\n",
    "# Run the initialization\n",
    "await initialize_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11f7b3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ User input handler ready!\n"
     ]
    }
   ],
   "source": [
    "# User Input Handler + logged agent steps\n",
    "async def process_user_input(user_input: str) -> str:\n",
    "    \"\"\"Process user input and return LLM response using MCP tools\"\"\"\n",
    "    if not agent_executor:\n",
    "        return \"Agent not initialized. Please run the initialization cell first.\"\n",
    "    \n",
    "    try:\n",
    "        # Use the agent to process the input and get intermediate steps\n",
    "        result = await agent_executor.ainvoke({\"input\": user_input})\n",
    "        output = result.get(\"output\") or result.get(\"final_output\") or \"\"\n",
    "\n",
    "        # Print intermediate steps if present\n",
    "        steps = result.get(\"intermediate_steps\") or []\n",
    "        for step in steps:\n",
    "            action = None\n",
    "            observation = None\n",
    "            if isinstance(step, tuple) and len(step) == 2:\n",
    "                action, observation = step\n",
    "            elif isinstance(step, dict) and \"action\" in step:\n",
    "                action = step.get(\"action\")\n",
    "                observation = step.get(\"observation\")\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            tool_name = getattr(action, \"tool\", getattr(action, \"tool_name\", \"unknown\"))\n",
    "            tool_args = getattr(action, \"tool_input\", getattr(action, \"input\", None))\n",
    "            print(f\"\\n--- Tool: {tool_name}\")\n",
    "            print(f\"args: {tool_args}\")\n",
    "            if observation is not None:\n",
    "                print(f\"result: {observation}\")\n",
    "            print(\"---\\n\")\n",
    "\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        return f\"Error processing request: {str(e)}\"\n",
    "\n",
    "# Interactive function for easy testing\n",
    "async def ask_assistant(question: str):\n",
    "    \"\"\"Easy-to-use function for asking the menu assistant\"\"\"\n",
    "    print(f\"ðŸ§³ User: {question}\")\n",
    "    print(\"ðŸ¤– Assistant:\")\n",
    "    \n",
    "    response = await process_user_input(question)\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "print(\"ðŸ’¬ User input handler ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f513ca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 MCP tools: ['get_menu']\n",
      "MCP HTTP server connected successfully!\n",
      "Available tools: ['get_menu']\n",
      "  - get_menu: Get menu information for a specific restaurant\n",
      "\n",
      "Args:\n",
      "    restaurantId: The ID of the restaurant\n",
      "\n",
      "Returns:\n",
      "    A dictionary containing the menu information or an error message\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test MCP server connectivity and tools\n",
    "async def test_mcp_connection():\n",
    "    \"\"\"Test MCP server connection and list available tools\"\"\"\n",
    "    tools = await create_mcp_tools()\n",
    "    if tools:\n",
    "        print(f\"MCP HTTP server connected successfully!\")\n",
    "        print(f\"Available tools: {[tool.name for tool in tools]}\")\n",
    "        for tool in tools:\n",
    "            print(f\"  - {tool.name}: {tool.description}\")\n",
    "    else:\n",
    "        print(\"Failed to connect to MCP HTTP server\")\n",
    "\n",
    "# Test MCP HTTP connection\n",
    "await test_mcp_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea438d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§³ User: What are all the gluten-free menu items available using restaurantId 2?\n",
      "ðŸ¤– Assistant:\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_menu` with `{'restaurantId': 2}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\n",
      "  \"id\": 2,\n",
      "  \"name\": \"Sushi World\",\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"name\": \"California Roll\",\n",
      "      \"price\": 8.99,\n",
      "      \"size\": null,\n",
      "      \"description\": \"Crab, avocado, and cucumber roll.\",\n",
      "      \"is_popular\": true,\n",
      "      \"dietary_info\": [\n",
      "        \"gluten-free\",\n",
      "        \"shellfish\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Spicy Tuna Roll\",\n",
      "      \"price\": 9.99,\n",
      "      \"size\": null,\n",
      "      \"description\": \"Tuna with spicy mayo.\",\n",
      "      \"is_popular\": false,\n",
      "      \"dietary_info\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Vegan Avocado Roll (GF)\",\n",
      "      \"price\": 7.99,\n",
      "      \"size\": null,\n",
      "      \"description\": \"Fresh avocado roll.\",\n",
      "      \"is_popular\": false,\n",
      "      \"dietary_info\": [\n",
      "        \"vegan\",\n",
      "        \"gluten-free\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Miso Soup\",\n",
      "      \"price\": 3.99,\n",
      "      \"size\": null,\n",
      "      \"description\": \"Traditional Japanese soup with tofu and seaweed.\",\n",
      "      \"is_popular\": true,\n",
      "      \"dietary_info\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Tempura Udon\",\n",
      "      \"price\": 12.99,\n",
      "      \"size\": null,\n",
      "      \"description\": \"Udon noodles with tempura shrimp and vegetables.\",\n",
      "      \"is_popular\": false,\n",
      "      \"dietary_info\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Green Tea Ice Cream\",\n",
      "      \"price\": 4.99,\n",
      "      \"size\": null,\n",
      "      \"description\": \"Creamy green tea flavored ice cream.\",\n",
      "      \"is_popular\": false,\n",
      "      \"dietary_info\": [\n",
      "        \"vegetarian\",\n",
      "        \"gluten-free\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"location\": \"456 Ocean Ave, Seaside City\",\n",
      "  \"cuisine\": \"Japanese\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3mHere are all gluten-free items on Sushi World (restaurantId 2) based on the current menu data:\n",
      "\n",
      "- California Roll â€” $8.99 â€” Gluten-free\n",
      "  - Crab, avocado, and cucumber roll. Note: shellfish present; confirm if gluten-free soy sauce or tamari is used if served with soy.\n",
      "\n",
      "- Vegan Avocado Roll (GF) â€” $7.99 â€” Gluten-free\n",
      "  - Fresh avocado roll; vegan.\n",
      "\n",
      "- Green Tea Ice Cream â€” $4.99 â€” Gluten-free\n",
      "  - Creamy green tea-flavored ice cream.\n",
      "\n",
      "Items not clearly marked as gluten-free (and should be confirmed with staff):\n",
      "- Miso Soup â€” $3.99\n",
      "- Tempura Udon â€” $12.99\n",
      "\n",
      "Would you like me to check cross-contamination notes for these GF items or pull any additional GF options from this restaurant?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Here are all gluten-free items on Sushi World (restaurantId 2) based on the current menu data:\n",
      "\n",
      "- California Roll â€” $8.99 â€” Gluten-free\n",
      "  - Crab, avocado, and cucumber roll. Note: shellfish present; confirm if gluten-free soy sauce or tamari is used if served with soy.\n",
      "\n",
      "- Vegan Avocado Roll (GF) â€” $7.99 â€” Gluten-free\n",
      "  - Fresh avocado roll; vegan.\n",
      "\n",
      "- Green Tea Ice Cream â€” $4.99 â€” Gluten-free\n",
      "  - Creamy green tea-flavored ice cream.\n",
      "\n",
      "Items not clearly marked as gluten-free (and should be confirmed with staff):\n",
      "- Miso Soup â€” $3.99\n",
      "- Tempura Udon â€” $12.99\n",
      "\n",
      "Would you like me to check cross-contamination notes for these GF items or pull any additional GF options from this restaurant?\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ EXAMPLE USAGE - Run this cell after setting up your API key!\n",
    "\n",
    "# Simple question\n",
    "await ask_assistant(\"What are all the popular menu items available using restaurantId 2?\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Weather + attractions\n",
    "# await ask_assistant(\"I'm planning to visit paris tomorrow. What's the weather like and what attractions should I visit?\")\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f083707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive chat loop â€” keep asking questions until you exit\n",
    "\n",
    "# try -\n",
    "# give me a random attraction\n",
    "# what about attractions in paris\n",
    "# more details on eiffel tower\n",
    "# book eiffel tower\n",
    "\n",
    "\n",
    "async def chat_loop():\n",
    "    print(\"Type 'exit' to quit. Press Enter on an empty line to skip.\")\n",
    "    while True:\n",
    "        try:\n",
    "            question = input(\"You: \").strip()\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            print(\"\\nExiting.\")\n",
    "            break\n",
    "        if not question:\n",
    "            continue\n",
    "        if question.lower() in (\"exit\", \"quit\", \"q\"):\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        await ask_assistant(question)\n",
    "\n",
    "# Start the loop\n",
    "await chat_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04302e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup function for HTTP MCP client\n",
    "async def cleanup_mcp():\n",
    "    \"\"\"Cleanup MCP client and server resources\"\"\"\n",
    "    global mcp_client\n",
    "    if mcp_client:\n",
    "        try:\n",
    "            await mcp_client.close()\n",
    "            print(\"MCP client closed\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error closing MCP client: {e}\")\n",
    "        mcp_client = None\n",
    "\n",
    "print(\"ðŸ§¹ Cleanup function ready!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
