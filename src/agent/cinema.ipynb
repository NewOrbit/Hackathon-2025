{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26927c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: c:\\Users\\AndrzejPytel\\source\\Hackathon-2025-AP-Fork\\.venv\\Scripts\\python.exe\n",
      "uv: c:\\Users\\AndrzejPytel\\source\\Hackathon-2025-AP-Fork\\.venv\\Scripts\\uv.EXE\n"
     ]
    }
   ],
   "source": [
    "# Step to ensure that the venv is being used for the project not local copies, should point at .venv in project.\n",
    "import sys, shutil\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"uv:\", shutil.which(\"uv\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba67892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uv in c:\\users\\andrzejpytel\\source\\hackathon-2025-ap-fork\\.venv\\lib\\site-packages (0.8.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.7 environment at: c:\\Users\\AndrzejPytel\\source\\Hackathon-2025-AP-Fork\\.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m13 packages\u001b[0m \u001b[2min 38ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# installs into the current Jupyter kernel environment\n",
    "%pip install -U uv \n",
    "#! to run shell commands\n",
    "!uv pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86c12d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated imports with official MCP adapter loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# LangChain + MCP Setup for Cinema Booking (HTTP-based for Jupyter)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Official MCP adapter imports for HTTP transport\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ Updated imports with official MCP adapter loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60c8345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Cinema MCP HTTP adapter setup ready!\n"
     ]
    }
   ],
   "source": [
    "# MCP Client Setup using Official Adapter with HTTP Transport\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Global MCP client for HTTP\n",
    "mcp_client = None\n",
    "\n",
    "async def create_mcp_tools():\n",
    "    \"\"\"Create MCP tools using the official LangChain MCP adapter with HTTP transport\"\"\"\n",
    "    global mcp_client\n",
    "    \n",
    "    try:\n",
    "        # Create MultiServerMCPClient with streamable_http transport for cinema\n",
    "        mcp_client = MultiServerMCPClient({\n",
    "            \"cinema\": {\n",
    "                \"transport\": \"streamable_http\",\n",
    "                \"url\": \"http://localhost:8010\"  # Cinema MCP server on port 8010\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Get tools from the MCP server\n",
    "        tools = await mcp_client.get_tools()\n",
    "        print(f\"Loaded {len(tools)} MCP tools: {[tool.name for tool in tools]}\")\n",
    "        return tools\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Cinema MCP HTTP server: {e}\")\n",
    "        print(\"Make sure the cinema MCP server is running on port 8010\")\n",
    "        print(\"Run: cd src/mcp/cinema-mcp && uv run mcp dev main.py\")\n",
    "        return []\n",
    "\n",
    "print(\"🔗 Cinema MCP HTTP adapter setup ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e4f778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Ready to load Cinema MCP tools via official adapter!\n"
     ]
    }
   ],
   "source": [
    "# Load MCP Tools using Official Adapter\n",
    "# The tools will be loaded dynamically when setting up the agent\n",
    "# No need to manually create tool wrappers - the adapter handles this automatically\n",
    "print(\"🛠️ Ready to load Cinema MCP tools via official adapter!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "501c5c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Cinema agent setup function ready! Run the next cell to initialize.\n"
     ]
    }
   ],
   "source": [
    "async def setup_agent():\n",
    "    \"\"\"Setup LangChain agent with Cinema MCP tools using official adapter\"\"\"\n",
    "    \n",
    "    # Initialize LLM for Azure OpenAI\n",
    "    # can get this from Azure Open AI service -> Azure AI Foundry Portal\n",
    "    from langchain_openai import AzureChatOpenAI\n",
    "    \n",
    "    llm = AzureChatOpenAI(\n",
    "        deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),  # Your Azure deployment name\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "        api_version=os.getenv(\"AZURE_API_VERSION\"), \n",
    "        temperature=1\n",
    "    )\n",
    "    \n",
    "    # Load MCP tools using official adapter\n",
    "    tools = await create_mcp_tools()\n",
    "    \n",
    "    if not tools:\n",
    "        print(\"No MCP tools loaded. Make sure the Cinema MCP server is accessible.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loaded {len(tools)} MCP tools: {[tool.name for tool in tools]}\")\n",
    "    \n",
    "    # Create system prompt for cinema assistant\n",
    "    system_prompt = \"\"\"You are a helpful cinema assistant that can help users discover movies and make reservations.\n",
    "    \n",
    "    You have access to cinema MCP tools for movie showings, including:\n",
    "    - Getting current movies playing with showtimes and availability\n",
    "    - Searching for movies by title, genre, date, room, and seat availability\n",
    "    - Getting detailed information about specific movie showings\n",
    "    - Making movie reservations for customers\n",
    "    - Viewing customer reservations\n",
    "    - Canceling reservations\n",
    "    \n",
    "    When helping users:\n",
    "    1. Use get_current_movies or search_movies to show available options\n",
    "    2. Use get_movie_details with exact title, date, time, and room for specific showings\n",
    "    3. For reservations, always collect: customer name, email, number of seats wanted\n",
    "    4. Use make_reservation with the exact movie details from search results\n",
    "    5. Be helpful and provide clear information about showtimes, pricing, and availability\n",
    "    \n",
    "    Always be friendly and guide users through the movie booking process step by step.\"\"\"\n",
    "    \n",
    "    # Create prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    \n",
    "    # Create agent\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "    # memory\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    # Create agent executor with tool logging callback and verbose output\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)\n",
    "    \n",
    "    return agent_executor\n",
    "\n",
    "# Initialize the agent (now async)\n",
    "agent_executor = None\n",
    "print(\"🤖 Cinema agent setup function ready! Run the next cell to initialize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688da57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing cinema agent with MCP tools...\n",
      "Error connecting to Cinema MCP HTTP server: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "Make sure the cinema MCP server is running on port 8010\n",
      "Run: cd src/mcp/cinema-mcp && uv run mcp dev main.py\n",
      "No MCP tools loaded. Make sure the Cinema MCP server is accessible.\n",
      "Failed to initialize agent. Check Cinema MCP server connection.\n",
      "Error connecting to Cinema MCP HTTP server: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "Make sure the cinema MCP server is running on port 8010\n",
      "Run: cd src/mcp/cinema-mcp && uv run mcp dev main.py\n",
      "No MCP tools loaded. Make sure the Cinema MCP server is accessible.\n",
      "Failed to initialize agent. Check Cinema MCP server connection.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent with Cinema MCP tools\n",
    "async def initialize_agent():\n",
    "    \"\"\"Initialize the agent with Cinema MCP tools\"\"\"\n",
    "    global agent_executor\n",
    "    print(\"Initializing cinema agent with MCP tools...\")\n",
    "    agent_executor = await setup_agent()\n",
    "    if agent_executor:\n",
    "        print(\"LangChain cinema agent with MCP tools ready!\")\n",
    "    else:\n",
    "        print(\"Failed to initialize agent. Check Cinema MCP server connection.\")\n",
    "\n",
    "# Run the initialization\n",
    "await initialize_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc7277da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 Cinema user input handler ready!\n"
     ]
    }
   ],
   "source": [
    "# User Input Handler + logged agent steps\n",
    "async def process_user_input(user_input: str) -> str:\n",
    "    \"\"\"Process user input and return LLM response using Cinema MCP tools\"\"\"\n",
    "    if not agent_executor:\n",
    "        return \"Agent not initialized. Please run the initialization cell first.\"\n",
    "    \n",
    "    try:\n",
    "        # Use the agent to process the input and get intermediate steps\n",
    "        result = await agent_executor.ainvoke({\"input\": user_input})\n",
    "        output = result.get(\"output\") or result.get(\"final_output\") or \"\"\n",
    "\n",
    "        # Print intermediate steps if present\n",
    "        steps = result.get(\"intermediate_steps\") or []\n",
    "        for step in steps:\n",
    "            action = None\n",
    "            observation = None\n",
    "            if isinstance(step, tuple) and len(step) == 2:\n",
    "                action, observation = step\n",
    "            elif isinstance(step, dict) and \"action\" in step:\n",
    "                action = step.get(\"action\")\n",
    "                observation = step.get(\"observation\")\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            tool_name = getattr(action, \"tool\", getattr(action, \"tool_name\", \"unknown\"))\n",
    "            tool_args = getattr(action, \"tool_input\", getattr(action, \"input\", None))\n",
    "            print(f\"\\n--- Tool: {tool_name}\")\n",
    "            print(f\"args: {tool_args}\")\n",
    "            if observation is not None:\n",
    "                print(f\"result: {observation}\")\n",
    "            print(\"---\\n\")\n",
    "\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        return f\"Error processing request: {str(e)}\"\n",
    "\n",
    "# Interactive function for easy testing\n",
    "async def ask_assistant(question: str):\n",
    "    \"\"\"Easy-to-use function for asking the cinema assistant\"\"\"\n",
    "    print(f\"🎬 User: {question}\")\n",
    "    print(\"🤖 Assistant:\")\n",
    "    \n",
    "    response = await process_user_input(question)\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "print(\"💬 Cinema user input handler ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c70994e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error connecting to Cinema MCP HTTP server: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "Make sure the cinema MCP server is running on port 8010\n",
      "Run: cd src/mcp/cinema-mcp && uv run mcp dev main.py\n",
      "Failed to connect to Cinema MCP HTTP server\n",
      "Make sure to start the cinema MCP server first:\n",
      "cd src/mcp/cinema-mcp && uv run mcp dev main.py\n"
     ]
    }
   ],
   "source": [
    "# Test Cinema MCP server connectivity and tools\n",
    "async def test_mcp_connection():\n",
    "    \"\"\"Test Cinema MCP server connection and list available tools\"\"\"\n",
    "    tools = await create_mcp_tools()\n",
    "    if tools:\n",
    "        print(f\"Cinema MCP HTTP server connected successfully!\")\n",
    "        print(f\"Available tools: {[tool.name for tool in tools]}\")\n",
    "        for tool in tools:\n",
    "            print(f\"  - {tool.name}: {tool.description}\")\n",
    "    else:\n",
    "        print(\"Failed to connect to Cinema MCP HTTP server\")\n",
    "        print(\"Make sure to start the cinema MCP server first:\")\n",
    "        print(\"cd src/mcp/cinema-mcp && uv run mcp dev main.py\")\n",
    "\n",
    "# Test Cinema MCP HTTP connection\n",
    "await test_mcp_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1551f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 User: What movies are currently playing?\n",
      "🤖 Assistant:\n",
      "Agent not initialized. Please run the initialization cell first.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 🚀 EXAMPLE USAGE - Run this cell after setting up your API key!\n",
    "\n",
    "# Simple question about current movies\n",
    "await ask_assistant(\"What movies are currently playing?\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Search for specific type of movie\n",
    "# await ask_assistant(\"I'm looking for action movies playing tomorrow. What do you have?\")\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9295d748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 Welcome to MovieMagic Cinema Assistant!\n",
      "I can help you find movies, check showtimes, and make reservations.\n",
      "Type 'exit' to quit. Press Enter on an empty line to skip.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interactive chat loop — keep asking questions until you exit\n",
    "\n",
    "# Try these example questions:\n",
    "# - \"What movies are playing today?\"\n",
    "# - \"Show me action movies\"\n",
    "# - \"I want to see Avatar tomorrow evening\"\n",
    "# - \"Get me details for Avatar on 2025-09-25 at 19:30 in theater_a\"\n",
    "# - \"Book 2 seats for Avatar on 2025-09-25 at 19:30 in theater_a for John Doe, john@email.com\"\n",
    "# - \"Show my reservations for john@email.com\"\n",
    "\n",
    "async def chat_loop():\n",
    "    print(\"🎬 Welcome to MovieMagic Cinema Assistant!\")\n",
    "    print(\"I can help you find movies, check showtimes, and make reservations.\")\n",
    "    print(\"Type 'exit' to quit. Press Enter on an empty line to skip.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            question = input(\"You: \").strip()\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            print(\"\\nExiting.\")\n",
    "            break\n",
    "        if not question:\n",
    "            continue\n",
    "        if question.lower() in (\"exit\", \"quit\", \"q\"):\n",
    "            print(\"🎬 Thanks for using MovieMagic Cinema! Goodbye!\")\n",
    "            break\n",
    "        await ask_assistant(question)\n",
    "\n",
    "# Start the cinema chat loop\n",
    "await chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70dad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup function for HTTP MCP client\n",
    "async def cleanup_mcp():\n",
    "    \"\"\"Cleanup MCP client and server resources\"\"\"\n",
    "    global mcp_client\n",
    "    if mcp_client:\n",
    "        try:\n",
    "            await mcp_client.close()\n",
    "            print(\"Cinema MCP client closed\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error closing Cinema MCP client: {e}\")\n",
    "        mcp_client = None\n",
    "\n",
    "print(\"🧹 Cleanup function ready!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
